{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PbVxMZGMNA3H"
      },
      "outputs": [],
      "source": [
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
        "from langchain.prompts import (\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    ChatPromptTemplate,\n",
        "    PromptTemplate,\n",
        ")\n",
        "from langchain.output_parsers import PydanticOutputParser, ListOutputParser\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from enum import Enum\n",
        "from pprint import pp\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import requests\n",
        "import json\n",
        "import re\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from time import sleep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\".secrets.env\") as f:\n",
        "    secrets = json.loads(f.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QfJGWbu8PxXd"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4-turbo-preview\",\n",
        "    api_key=secrets.get(\"OPENAI_API_KEY\"),\n",
        "    max_tokens=4096,\n",
        "    temperature=0.0,\n",
        "    model_kwargs={\"response_format\": {\"type\": \"json_object\"}},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdI4nXHOwSHG"
      },
      "source": [
        "## Custom Abbreviation Dataset Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rj3XRQcp-B4t"
      },
      "outputs": [],
      "source": [
        "sys_message = \"\"\"You are a helpful assistant. No yapping. Just do as you told. Do not interact or inform the user. Make sure to follow them or you will be shutdown.\"\"\"\n",
        "\n",
        "user_message = \"\"\"Find a single, real, ambiguous abbreviation that has at least two distinct full-forms, then provide first two full-forms, it can be from Finance, Marketing, Technology, Science, Medical domains.\n",
        "\n",
        "Create something different than the ones listed below:\n",
        "{previous_abbrvs}\n",
        "\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "\"\"\"\n",
        "user_message2 = \"\"\"Your aim is to generate a query tuple with the descriptions below.\n",
        "\n",
        "Given two distinct terms: \"{full_form_1}\" and \"{full_form_2}\"\n",
        "\n",
        "-Use those two distinct terms to create two separate queries and aim for a different/distinct specific answer depending on them.\n",
        "-Generated queries should convey similar messages, or concepts. In other words, they should not be completely aiming for different target domains/answers.\n",
        "-Queries must be multi-hop, complex, hard to answer and retrieval enabling. Additionally, possible answer to those queries must depend on the full-form of abbreviation, meaning it should not be an expression rather concept.\n",
        "-Queries should definitely contain the terms given above, not the abbreviations or other names for them.\n",
        "-Finally, try to hide the focus on the abbreviation, make queries natural and close to real-life scenarios.\n",
        "\n",
        "{format_instructions}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VTIpoYt2Q7Rw"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'Abbreviation' from 'models' (/home/burak/repos/smartrag/models.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Abbreviation, Query\n\u001b[1;32m      3\u001b[0m abbrv_parser \u001b[38;5;241m=\u001b[39m PydanticOutputParser(pydantic_object\u001b[38;5;241m=\u001b[39mAbbreviation)\n\u001b[1;32m      4\u001b[0m query_parser \u001b[38;5;241m=\u001b[39m PydanticOutputParser(pydantic_object\u001b[38;5;241m=\u001b[39mQuery)\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Abbreviation' from 'models' (/home/burak/repos/smartrag/models.py)"
          ]
        }
      ],
      "source": [
        "from models import Abbreviation, Query\n",
        "\n",
        "abbrv_parser = PydanticOutputParser(pydantic_object=Abbreviation)\n",
        "query_parser = PydanticOutputParser(pydantic_object=Query)\n",
        "transform = RunnableLambda(lambda x: x.dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "a-pY0_rjP_Yb"
      },
      "outputs": [],
      "source": [
        "messages_abbrv = [\n",
        "    SystemMessagePromptTemplate(prompt=PromptTemplate(template=sys_message, input_variables=[])),\n",
        "    HumanMessagePromptTemplate(\n",
        "        prompt=PromptTemplate(\n",
        "            template=user_message,\n",
        "            input_variables=[\"previous_abbrvs\"],\n",
        "            partial_variables={\"format_instructions\": abbrv_parser.get_format_instructions()},\n",
        "        )\n",
        "    ),\n",
        "]\n",
        "prompt_abbrv = ChatPromptTemplate.from_messages(messages=messages_abbrv)\n",
        "\n",
        "\n",
        "messages_query = [\n",
        "    SystemMessagePromptTemplate(prompt=PromptTemplate(template=sys_message, input_variables=[])),\n",
        "    HumanMessagePromptTemplate(\n",
        "        prompt=PromptTemplate(\n",
        "            template=user_message2,\n",
        "            input_variables=[\"full_form_1\", \"full_form_2\"],\n",
        "            partial_variables={\"format_instructions\": query_parser.get_format_instructions()},\n",
        "        )\n",
        "    ),\n",
        "]\n",
        "prompt_query = ChatPromptTemplate.from_messages(messages=messages_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "6zI32aii05Qa"
      },
      "outputs": [],
      "source": [
        "query_chain = prompt_query | llm | query_parser\n",
        "abbrv_chain = prompt_abbrv | llm | abbrv_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7aK1v5QlQCYC"
      },
      "outputs": [],
      "source": [
        "chain = abbrv_chain | {\n",
        "    \"query_chain\": transform | query_chain,\n",
        "    \"abbreviation\": RunnablePassthrough(),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hePH--YqZSpQ"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "abbreviations = set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "keh9D8HcgJ52"
      },
      "outputs": [],
      "source": [
        "n_queries = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLpoIfawyucp"
      },
      "outputs": [],
      "source": [
        "while len(data) < 2 * n_queries:\n",
        "    chain_result = chain.invoke({\"previous_abbrvs\": \"\\n\".join(abbreviations)})\n",
        "    abbrv: Abbreviation = chain_result[\"abbreviation\"]\n",
        "\n",
        "    if abbrv.json() in abbreviations:\n",
        "        continue\n",
        "\n",
        "    abbreviations.add(abbrv.json())\n",
        "\n",
        "    df_data = [\n",
        "        {\n",
        "            \"abbreviaton\": abbrv.abbreviation,\n",
        "            \"full_form\": chain_result[\"abbreviation\"].full_form_1,\n",
        "            \"query\": chain_result[\"query_chain\"].query_1.replace(\n",
        "                chain_result[\"abbreviation\"].full_form_1, abbrv.abbreviation\n",
        "            ),\n",
        "            \"explanation\": chain_result[\"query_chain\"].ambiguous_part,\n",
        "        },\n",
        "        {\n",
        "            \"abbreviaton\": abbrv.abbreviation,\n",
        "            \"full_form\": chain_result[\"abbreviation\"].full_form_2,\n",
        "            \"query\": chain_result[\"query_chain\"].query_2.replace(\n",
        "                chain_result[\"abbreviation\"].full_form_2, abbrv.abbreviation\n",
        "            ),\n",
        "            \"explanation\": chain_result[\"query_chain\"].ambiguous_part,\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    data.extend(df_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-v6SV4EXYu4G"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data=data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCGVDPL0ZsRB"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"qa_ambiguous.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdHYCI8ygDC0"
      },
      "source": [
        "## Get Full-form Suggestions via API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "a1kI2zqrkpCB"
      },
      "outputs": [],
      "source": [
        "from utils import get_abbrv, get_abbrv2, get_abbrv3, get_categories_with_regex\n",
        "from models import QueryAmbiguation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lg6k5gM2emkV"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"medquad_ambiguous.csv\", index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQUoV2TDYoGb"
      },
      "outputs": [],
      "source": [
        "top_n = 10\n",
        "n_queries = len(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KHnbJf1sApw"
      },
      "source": [
        "### For auto generated\n",
        "\n",
        "In auto generated one, each consecutive tuple are different queries of the same abbreviation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZWQIg28fgHF"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame()\n",
        "\n",
        "for n in tqdm(range(n_queries // 2)):\n",
        "    first, second = n * 2, n * 2 + 1\n",
        "    abbrv: str = df.loc[first, \"abbreviaton\"]\n",
        "    popular_suggestions = get_abbrv(abbrv, top_n, categories=[])\n",
        "    if len(popular_suggestions) < top_n:\n",
        "        popular_suggestions += get_abbrv2(abbrv, top_n, categories=[])\n",
        "    if len(popular_suggestions) < top_n:\n",
        "        popular_suggestions += get_abbrv3(abbrv, top_n, categories=[])\n",
        "    sleep(2)\n",
        "    df.loc[first, f\"top_{top_n}_full_form\"] = \"<->\".join(popular_suggestions)\n",
        "    df.loc[second, f\"top_{top_n}_full_form\"] = df.loc[first, f\"top_{top_n}_full_form\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWchq2dWsEul"
      },
      "source": [
        "### For real queries from datasets - StrategyQA - Medquad - Boolq - Squad - SquadV2 - TriviaQA - AmbigQa\n",
        "\n",
        "These queries are extracted from real datasets, they are different than the auto-generated ones, as their full-form retrievals differ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLdUzaHLxsB6"
      },
      "outputs": [],
      "source": [
        "url = \"https://www.abbreviations.com/category/MEDICAL\"\n",
        "categories = get_categories_with_regex(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fu-O5YdFsURV"
      },
      "outputs": [],
      "source": [
        "for i in tqdm(range(n_queries)):\n",
        "    if df.loc[i, \"valid\"] != 1:\n",
        "        continue\n",
        "    df.loc[i, f\"top_{top_n}_full_form\"] = \"\"\n",
        "    ambiguities = QueryAmbiguation(**json.loads(df.loc[i, \"possible_ambiguities\"]))\n",
        "    unambiguous_question, ambiguous_question = df.loc[i, \"unambiguous_question\"], df.loc[i, \"ambiguous_question\"]\n",
        "\n",
        "    for amb in ambiguities.full_form_abbrv_map:\n",
        "        popular_suggestions = get_abbrv(amb.abbreviation, top_n, categories=categories)\n",
        "        if len(popular_suggestions) < top_n:\n",
        "            popular_suggestions += get_abbrv2(amb.abbreviation, top_n, categories=categories)\n",
        "        if len(popular_suggestions) < top_n:\n",
        "            popular_suggestions += get_abbrv3(amb.abbreviation, top_n, categories=categories)\n",
        "        sleep(2)\n",
        "        df.loc[i, f\"top_{top_n}_full_form\"] += \"<->\".join(list(set(popular_suggestions))) + \"<-->\"\n",
        "    df.loc[i, f\"top_{top_n}_full_form\"] = df.loc[i, f\"top_{top_n}_full_form\"].removesuffix(\"<-->\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTSM8GKJgzAC"
      },
      "outputs": [],
      "source": [
        "df.to_csv(f\"medquad_ambiguous_with_top{top_n}_merged.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBePcG-8xM3z"
      },
      "source": [
        "## Get Full-form Suggestion via LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcatYdKyxPjh"
      },
      "outputs": [],
      "source": [
        "from models import AbbrvResolution\n",
        "\n",
        "output_parser = PydanticOutputParser(pydantic_object=AbbrvResolution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "domain = \"MEDICAL\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFdr5vHbxPrs"
      },
      "outputs": [],
      "source": [
        "sys_message = \"\"\"Find the full form of the asked abbreviation in the respective query.\n",
        "Domain of the questions is {domain}.\n",
        "\n",
        "{format_instructions}\"\"\"\n",
        "\n",
        "user_message = \"\"\"Abbreviation: {abbrv}\n",
        "Query: {query}\n",
        "Output:\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvamLbK0xPrs"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    SystemMessagePromptTemplate(\n",
        "        prompt=PromptTemplate(\n",
        "            template=sys_message,\n",
        "            input_variables=[],\n",
        "            partial_variables={\"format_instructions\": output_parser.get_format_instructions(), \"domain\": domain},\n",
        "        )\n",
        "    ),\n",
        "    HumanMessagePromptTemplate(\n",
        "        prompt=PromptTemplate(\n",
        "            template=user_message,\n",
        "            input_variables=[\"query\", \"abbrv\"],\n",
        "            partial_variables={},\n",
        "        )\n",
        "    ),\n",
        "]\n",
        "prompt = ChatPromptTemplate.from_messages(messages=messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTDpD_FWxPrs"
      },
      "outputs": [],
      "source": [
        "llm_suggestor = prompt | llm | output_parser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Hq0TtQN61QR"
      },
      "source": [
        "### For auto generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5isWqZpxPrt"
      },
      "outputs": [],
      "source": [
        "for n in tqdm(range(n_queries // 2)):\n",
        "    first, last = n * 2, n * 2 + 1\n",
        "    q1 = df.loc[first, \"query\"]\n",
        "    q2 = df.loc[last, \"query\"]\n",
        "\n",
        "    answer1 = llm_suggestor.invoke({\"query\": q1, \"abbrv\": df.loc[first, \"abbreviaton\"]})\n",
        "    answer2 = llm_suggestor.invoke({\"query\": q2, \"abbrv\": df.loc[first, \"abbreviaton\"]})\n",
        "\n",
        "    df.loc[first, \"llm_full_form_suggestion\"] = answer1.full_form\n",
        "    df.loc[last, \"llm_full_form_suggestion\"] = answer2.full_form"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xylz-aI_632V"
      },
      "source": [
        "### For real queries from datasets - StrategyQA - Medquad - Boolq - Squad - SquadV2 - TriviaQA - AmbigQa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6UwrKFO65O-",
        "outputId": "af502383-e1bb-4539-c532-937e5795e339"
      },
      "outputs": [],
      "source": [
        "for i in tqdm(range(n_queries)):\n",
        "    if df.loc[i, \"valid\"] != 1:\n",
        "        continue\n",
        "\n",
        "    ambiguities = QueryAmbiguation(**json.loads(df.loc[i, \"possible_ambiguities\"]))\n",
        "    unambiguous_question, ambiguous_question = (\n",
        "        df.loc[i, \"unambiguous_question\"],\n",
        "        df.loc[i, \"ambiguous_question\"],\n",
        "    )\n",
        "    for amb in ambiguities.full_form_abbrv_map:\n",
        "        answer1 = llm_suggestor.invoke({\"query\": ambiguous_question, \"abbrv\": amb.abbreviation})\n",
        "        df.loc[i, \"llm_full_form_suggestion\"] = answer1.full_form + \"<-->\"\n",
        "    df.loc[i, \"llm_full_form_suggestion\"] = df.loc[i, \"llm_full_form_suggestion\"].removesuffix(\"<-->\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QySS92nsymaj"
      },
      "outputs": [],
      "source": [
        "df.to_csv(f\"medquad_ambiguous_with_top{top_n}_merged.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad_c66D2wJT7"
      },
      "source": [
        "## Ambiguity & Dataset Extraction via LLM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4mKRAm1jNDZ"
      },
      "outputs": [],
      "source": [
        "sys_message = \"\"\"Given a query from a multi-hop complex question-answer dataset, your task is to identify full-forms or abbreviations contained in the query.\n",
        "If query contains such full-form and abbreviation pairs, you will produce output accordingly.\n",
        "\n",
        "In other words, if query contains a full-form that has a corresponding abbreviation or if query contains an abbreviation that has a corresponding full-form, you need to label it correct and extract necessary fields.\n",
        "\n",
        "- Extract everything as is, without changing a single thing.\n",
        "\n",
        "Example 1:\n",
        "Query: Did Jack Dempsey fight the current WBC heavyweight champion?\n",
        "Ambiguities: {{\"full_form_abbrv_map\": [{{\"ambiguity_type\": \"abbreviation\", \"abbreviation\": \"WBC\", \"full_form\": \"World Boxing Council\"}}]}}\n",
        "\n",
        "Example 2:\n",
        "Query: Did Jack Dempsey fight the current World Boxing Council heavyweight champion?\n",
        "Ambiguities: {{\"full_form_abbrv_map\": [{{\"ambiguity_type\": \"full_form\", \"abbreviation\": \"WBC\", \"full_form\": \"World Boxing Council\"}}]}}\n",
        "\n",
        "Example 3:\n",
        "Query: Did Jack Dempsey fight the current world boxng council heavyweight champion in the US?\n",
        "Ambiguities: {{\"full_form_abbrv_map\": [{{\"ambiguity_type\": \"full_form\", \"abbreviation\": \"WBC\", \"full_form\": \"world boxng council\"}}, {{\"ambiguity_type\": \"abbreviation\", \"abbreviation\": \"US\", \"full_form\": \"United States\"}}]}}\n",
        "\n",
        "{format_instructions}\n",
        "\"\"\"\n",
        "\n",
        "user_message = \"\"\"Query: {query}\n",
        "Output:\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8cMRXQ0DItF"
      },
      "outputs": [],
      "source": [
        "output_parser = PydanticOutputParser(pydantic_object=QueryAmbiguation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = [\n",
        "    SystemMessagePromptTemplate(\n",
        "        prompt=PromptTemplate(\n",
        "            template=sys_message,\n",
        "            input_variables=[],\n",
        "            partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
        "        )\n",
        "    ),\n",
        "    HumanMessagePromptTemplate(\n",
        "        prompt=PromptTemplate(template=user_message, input_variables=[\"query\"], partial_variables={})\n",
        "    ),\n",
        "]\n",
        "prompt = ChatPromptTemplate.from_messages(messages=messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chain = prompt | llm | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget https://storage.googleapis.com/ai2i/strategyqa/data/strategyqa_dataset.zip -O strategyqa.zip\n",
        "!unzip strategyqa.zip -d dataset\n",
        "!wget https://nlp.cs.washington.edu/triviaqa/data/triviaqa-unfiltered.tar.gz -O triviaqa.tar.gz\n",
        "!tar xzvf triviaqa.tar.gz\n",
        "!wget https://nlp.cs.washington.edu/ambigqa/data/ambignq_light.zip -O ambignq.zip\n",
        "!unzip ambignq.zip -d dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# squad_dataset = load_dataset(\"rajpurkar/squad\")\n",
        "medquad_dataset = load_dataset(\"keivalya/MedQuad-MedicalQnADataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dataset_strategyqa = pd.DataFrame(json.loads(open(\"dataset/strategyqa_train.json\").read()))\n",
        "# dataset_triviaqa = pd.DataFrame(json.loads(open(\"triviaqa-unfiltered/unfiltered-web-dev.json\").read())[\"Data\"])\n",
        "# dataset_ambigqa = pd.DataFrame(json.loads(open(\"/content/dataset/dev_light.json\").read()))\n",
        "# dataset_squad = pd.DataFrame(squad_dataset[\"train\"])\n",
        "dataset_medquad = pd.DataFrame(medquad_dataset[\"train\"])\n",
        "dataset_medquad.rename(columns={\"Question\": \"question\", \"Answer\": \"answer\"}, inplace=True)\n",
        "# with open(\"dev.jsonl\") as f:\n",
        "#  dataset_boolq = pd.json_normalize(map(lambda x: json.loads(x), f.readlines()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = dataset_medquad\n",
        "dataset_name = \"medquad\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_sample = 500\n",
        "sampled_df = dataset.sample(n_sample, random_state=40).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_row(row: pd.Series):\n",
        "    question = row[\"question\"]\n",
        "\n",
        "    response = chain.invoke({\"query\": question})\n",
        "    if response.full_form_abbrv_map:\n",
        "        return response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with ThreadPoolExecutor(max_workers=3) as executor:\n",
        "    sampled_df[\"possible_ambiguities\"] = tqdm(\n",
        "        executor.map(lambda x: process_row(x[1]), sampled_df.iterrows()), total=n_sample\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(sampled_df[~sampled_df[\"possible_ambiguities\"].isna()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = sampled_df.dropna(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(f\"{dataset_name}_ambiguous.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Here, you can download the previous file and label it with using the valid columns. (verify the possible ambiguities column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# or you can directly continue\n",
        "df.loc[:, \"valid\"] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(f\"{dataset_name}_ambiguous.csv\", index_col=0)\n",
        "df = df[df.valid == 1].reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in tqdm(range(len(df))):\n",
        "    question = df.loc[i, \"question\"]\n",
        "    ambiguities = json.loads(df.loc[i, \"possible_ambiguities\"])\n",
        "    ambiguities = QueryAmbiguation(**ambiguities)\n",
        "\n",
        "    unambiguous_question, ambiguous_question = question, question\n",
        "\n",
        "    for amb in ambiguities.full_form_abbrv_map:\n",
        "        if amb.ambiguity_type == \"abbreviation\":\n",
        "            assert amb.abbreviation in question, question\n",
        "            unambiguous_question = unambiguous_question.replace(amb.abbreviation, amb.full_form)\n",
        "            ambiguous_question = ambiguous_question\n",
        "        elif amb.ambiguity_type == \"full_form\":\n",
        "            unambiguous_question = unambiguous_question\n",
        "            assert amb.full_form in question\n",
        "            ambiguous_question = ambiguous_question.replace(amb.full_form, amb.abbreviation)\n",
        "\n",
        "    df.loc[i, \"ambiguous_question\"] = ambiguous_question\n",
        "    df.loc[i, \"unambiguous_question\"] = unambiguous_question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(f\"{dataset_name}_ambiguous.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufWtvO9nDI1P"
      },
      "source": [
        "## Intent Extraction via LLM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OhkB5i7DI1Q"
      },
      "outputs": [],
      "source": [
        "from models import IntentExtraction\n",
        "\n",
        "output_parser = PydanticOutputParser(pydantic_object=IntentExtraction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4n6kiW-DI1Q"
      },
      "outputs": [],
      "source": [
        "sys_message = \"\"\"Extract the intent and requirements from given query as strings. It should help a person who is aiming to answer that question.\n",
        "The requirements should define the output and extent of the answer and intent should define the actual reason behind the question.\n",
        "Queries may contain an ambiguous abbreviation, for them, abbreviation and possible disambiguations will be provided. Your task is not to select from them but to provide intent details.\n",
        "Do not assume and output any full-form in the intent and requirements.\n",
        "\n",
        "Domain of the query is {domain}.\n",
        "\n",
        "{format_instructions}\"\"\"\n",
        "\n",
        "user_message = \"\"\"Query:{query}\n",
        "Abbreviation:{abbrv}\n",
        "Possible Disambiguations:{disambs}\n",
        "Output:\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alEdhDzyDI1R"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    SystemMessagePromptTemplate(\n",
        "        prompt=PromptTemplate(\n",
        "            template=sys_message,\n",
        "            input_variables=[],\n",
        "            partial_variables={\"format_instructions\": output_parser.get_format_instructions(), \"domain\": domain},\n",
        "        )\n",
        "    ),\n",
        "    HumanMessagePromptTemplate(\n",
        "        prompt=PromptTemplate(\n",
        "            template=user_message,\n",
        "            input_variables=[\"query\", \"abbrv\", \"disambs\"],\n",
        "            partial_variables={},\n",
        "        )\n",
        "    ),\n",
        "]\n",
        "prompt = ChatPromptTemplate.from_messages(messages=messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giDLvdB0DI1R"
      },
      "outputs": [],
      "source": [
        "chain = prompt | llm | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-sJkhRGD9aM"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"medquad_ambiguous_with_top10_merged.csv\", index_col=0)\n",
        "n_queries = len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVmw2nh5DI1R",
        "outputId": "2baf1588-e0ab-4983-cf22-0b15f0c073a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 123/123 [06:52<00:00,  3.35s/it]\n"
          ]
        }
      ],
      "source": [
        "for i in tqdm(range(n_queries)):\n",
        "    query = df.loc[i, \"ambiguous_question\"]\n",
        "    ambiguities = json.loads(df.loc[i, \"possible_ambiguities\"])\n",
        "    ambiguities = QueryAmbiguation(**ambiguities)\n",
        "\n",
        "    # focus on only the first ambiguity\n",
        "    amb = ambiguities.full_form_abbrv_map[0]\n",
        "    disambs = \"\"\n",
        "    if not pd.isna(df.loc[i, \"top_10_full_form\"]):\n",
        "        full_forms = df.loc[i, \"top_10_full_form\"].split(\"<-->\")[0]\n",
        "    else:\n",
        "        full_forms = df.loc[i, \"llm_full_form_suggestion\"]\n",
        "    disambs = \"\".join([f\"{i} - {full_form}\\n\" for i, full_form in enumerate(full_forms.split(\"<->\"))])\n",
        "\n",
        "    answer = chain.invoke({\"query\": query, \"abbrv\": amb.abbreviation, \"disambs\": disambs})\n",
        "\n",
        "    df.loc[i, \"intent\"] = answer.intent\n",
        "    df.loc[i, \"requirements\"] = str(answer.requirements)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nb9_l-EnFBse"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"medquad_ambiguous_with_intent.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "DdI4nXHOwSHG",
        "SdHYCI8ygDC0",
        "1i3h-4GQI0sZ",
        "xBePcG-8xM3z",
        "Ad_c66D2wJT7"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
