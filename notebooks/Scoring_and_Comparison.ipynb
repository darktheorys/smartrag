{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/burak/repos/smartrag\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disambiguation_methods.qa import chain_answer\n",
    "from disambiguation_methods.score import chain_score\n",
    "from collections import defaultdict\n",
    "from disambiguation_methods.qa import AnswerStr\n",
    "from disambiguation_methods.score import AnswerJudge\n",
    "from langchain_core.runnables import RunnableLambda, RunnableParallel, RunnableConfig\n",
    "from models import QueryAmbiguation\n",
    "import pandas as pd\n",
    "import json\n",
    "from disambiguation_methods.domain_extractor import categories\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 10\n",
    "dataset_name = \"generated\"\n",
    "domain = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"./data/{dataset_name}_ambiguous_top{top_n}+DOMAIN+LLM+Intent+MLM+TE+LLM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm1 = RunnableLambda(lambda x: chain_answer.invoke(x[\"amb\"]))\n",
    "lm2 = RunnableLambda(lambda x: chain_answer.invoke(x[\"unamb\"]))\n",
    "lm3 = RunnableLambda(lambda x: chain_answer.invoke(x[\"disamb\"]))\n",
    "chain_ = RunnableParallel(amb=lm1, unamb=lm2, disamb=lm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['possible_ambiguities', 'question', 'top_10_full_form',\n",
       "       'ambiguous_question', 'unambiguous_question', 'domain_idx',\n",
       "       'top_10_full_form_sources', 'llm_full_form_suggestions', 'intent',\n",
       "       'MLM_ground_truth_full_form_prob', 'MLM_llm_full_form_suggestion_prob',\n",
       "       'MLM_most_likely_full_forms', 'MLM_most_likely_full_form_probs',\n",
       "       'MLM_most_likely_selection_types', 'MLM_top_10_full_form_probs',\n",
       "       'TE_ground_truth_full_form_prob', 'TE_llm_full_form_suggestion_prob',\n",
       "       'TE_most_likely_full_forms', 'TE_most_likely_full_form_probs',\n",
       "       'TE_most_likely_selection_types', 'TE_top_10_full_form_probs',\n",
       "       'LLM_most_likely_full_forms', 'LLM_most_likely_selection_types',\n",
       "       'disambiguated_question',\n",
       "       'MLM_disambiguated_question_answered_by_gpt35_correct',\n",
       "       'MLM_unambiguous_question_answered_by_gpt35_correct',\n",
       "       'MLM_ambiguous_question_answered_by_gpt35_correct',\n",
       "       'MLM_disambiguated_question_answered_by_gpt35',\n",
       "       'MLM_unambiguous_question_answered_by_gpt35',\n",
       "       'MLM_ambiguous_question_answered_by_gpt35',\n",
       "       'TE_disambiguated_question_answered_by_gpt35_correct',\n",
       "       'TE_unambiguous_question_answered_by_gpt35_correct',\n",
       "       'TE_ambiguous_question_answered_by_gpt35_correct',\n",
       "       'TE_disambiguated_question_answered_by_gpt35',\n",
       "       'TE_unambiguous_question_answered_by_gpt35',\n",
       "       'TE_ambiguous_question_answered_by_gpt35',\n",
       "       'LLM_disambiguated_question_answered_by_gpt35_correct',\n",
       "       'LLM_unambiguous_question_answered_by_gpt35_correct',\n",
       "       'LLM_ambiguous_question_answered_by_gpt35_correct',\n",
       "       'LLM_disambiguated_question_answered_by_gpt35',\n",
       "       'LLM_unambiguous_question_answered_by_gpt35',\n",
       "       'LLM_ambiguous_question_answered_by_gpt35'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:04<00:00,  3.65s/it]\n"
     ]
    }
   ],
   "source": [
    "evaluation = defaultdict(lambda: {\"amb\": [], \"disamb\": [], \"unamb\": []})\n",
    "\n",
    "for method in [\"LLM2\"]:\n",
    "    for df_index in tqdm(range(len(df))):\n",
    "        ambiguities = QueryAmbiguation(**json.loads(df.loc[df_index, \"possible_ambiguities\"]))\n",
    "        most_likely_full_forms: list[str] = json.loads(df.loc[df_index, f\"llm_full_form_suggestions\"])\n",
    "\n",
    "        disambiguated_question_answers = []\n",
    "        unambiguous_question_answers = []\n",
    "        ambiguous_question_answers = []\n",
    "\n",
    "        evaluation[method][\"amb\"].append([])\n",
    "        evaluation[method][\"unamb\"].append([])\n",
    "        evaluation[method][\"disamb\"].append([])\n",
    "\n",
    "        for full_form, amb in zip(most_likely_full_forms, ambiguities.full_form_abbrv_map):\n",
    "            amb_question: str = df.loc[df_index, \"ambiguous_question\"]\n",
    "            unamb_question: str = df.loc[df_index, \"unambiguous_question\"]\n",
    "\n",
    "            disambiguated_question = amb_question.replace(amb.abbreviation, amb.abbreviation + f\" ({full_form})\")\n",
    "            df.loc[df_index, \"disambiguated_question\"] = disambiguated_question\n",
    "\n",
    "            answer: str = df.loc[df_index, \"answer\"] if \"answer\" in df else \"\"\n",
    "\n",
    "            response: dict[str, AnswerStr] = chain_.invoke(\n",
    "                {\n",
    "                    \"amb\": {\n",
    "                        \"query\": amb_question,\n",
    "                        \"intent\": df.loc[df_index, \"intent\"],\n",
    "                        \"domain\": categories[df.loc[df_index, \"domain_idx\"]]\n",
    "                        if df.loc[df_index, \"domain_idx\"] < len(categories)\n",
    "                        else None,\n",
    "                    },\n",
    "                    \"unamb\": {\n",
    "                        \"query\": unamb_question,\n",
    "                        \"intent\": df.loc[df_index, \"intent\"],\n",
    "                        \"domain\": categories[df.loc[df_index, \"domain_idx\"]]\n",
    "                        if df.loc[df_index, \"domain_idx\"] < len(categories)\n",
    "                        else None,\n",
    "                    },\n",
    "                    \"disamb\": {\n",
    "                        \"query\": disambiguated_question,\n",
    "                        \"intent\": df.loc[df_index, \"intent\"],\n",
    "                        \"domain\": categories[df.loc[df_index, \"domain_idx\"]]\n",
    "                        if df.loc[df_index, \"domain_idx\"] < len(categories)\n",
    "                        else None,\n",
    "                    },\n",
    "                },\n",
    "                RunnableConfig(configurable={\"llm\": \"gpt35\"}),\n",
    "            )\n",
    "\n",
    "            response_: AnswerJudge = chain_score.invoke(\n",
    "                {\n",
    "                    \"answer\": answer if answer else response[\"unamb\"].answer,\n",
    "                    \"amb\": response[\"amb\"].answer,\n",
    "                    \"unamb\": response[\"unamb\"].answer,\n",
    "                    \"disamb\": response[\"disamb\"].answer,\n",
    "                    \"query\": unamb_question,\n",
    "                }\n",
    "            )\n",
    "            # amb, unamb, disamb\n",
    "\n",
    "            disambiguated_question_answers.append(response[\"disamb\"].answer)\n",
    "            unambiguous_question_answers.append(response[\"unamb\"].answer)\n",
    "            ambiguous_question_answers.append(response[\"amb\"].answer)\n",
    "\n",
    "            evaluation[method][\"amb\"][-1].append(response_.bit1 == 1)\n",
    "            evaluation[method][\"unamb\"][-1].append(response_.bit2 == 1)\n",
    "            evaluation[method][\"disamb\"][-1].append(response_.bit3 == 1)\n",
    "\n",
    "        df.loc[df_index, f\"{method}_disambiguated_question_answered_by_gpt35_correct\"] = json.dumps(\n",
    "            evaluation[method][\"disamb\"]\n",
    "        )\n",
    "        df.loc[df_index, f\"{method}_unambiguous_question_answered_by_gpt35_correct\"] = json.dumps(\n",
    "            evaluation[method][\"unamb\"]\n",
    "        )\n",
    "        df.loc[df_index, f\"{method}_ambiguous_question_answered_by_gpt35_correct\"] = json.dumps(\n",
    "            evaluation[method][\"amb\"]\n",
    "        )\n",
    "\n",
    "        df.loc[df_index, f\"{method}_disambiguated_question_answered_by_gpt35\"] = json.dumps(\n",
    "            disambiguated_question_answers\n",
    "        )\n",
    "        df.loc[df_index, f\"{method}_unambiguous_question_answered_by_gpt35\"] = json.dumps(unambiguous_question_answers)\n",
    "        df.loc[df_index, f\"{method}_ambiguous_question_answered_by_gpt35\"] = json.dumps(ambiguous_question_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_134784/3652028908.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  eval_df = pd.concat(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>ambiguous_accuracy</th>\n",
       "      <th>unambiguous_accuracy</th>\n",
       "      <th>disambiguated_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLM</td>\n",
       "      <td>0.953775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.911010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TE</td>\n",
       "      <td>0.952277</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LLM</td>\n",
       "      <td>0.945302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.930966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LLM2</td>\n",
       "      <td>0.959358</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.886698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  ambiguous_accuracy  unambiguous_accuracy  disambiguated_accuracy\n",
       "0    MLM            0.953775                   1.0                0.911010\n",
       "1     TE            0.952277                   1.0                0.973554\n",
       "2    LLM            0.945302                   1.0                0.930966\n",
       "3   LLM2            0.959358                   1.0                0.886698"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "eval_df = pd.DataFrame(columns=[\"method\", \"ambiguous_accuracy\", \"unambiguous_accuracy\", \"disambiguated_accuracy\"])\n",
    "\n",
    "for method in [\"MLM\", \"TE\", \"LLM\", \"LLM2\"]:\n",
    "    eval_df = pd.concat(\n",
    "        [\n",
    "            eval_df,\n",
    "            pd.DataFrame(\n",
    "                [\n",
    "                    {\n",
    "                        \"method\": method,\n",
    "                        \"ambiguous_accuracy\": df[f\"{method}_ambiguous_question_answered_by_gpt35_correct\"]\n",
    "                        .apply(lambda x: np.mean(json.loads(x)))\n",
    "                        .mean(),\n",
    "                        \"unambiguous_accuracy\": df[f\"{method}_unambiguous_question_answered_by_gpt35_correct\"]\n",
    "                        .apply(lambda x: np.mean(json.loads(x)))\n",
    "                        .mean(),\n",
    "                        \"disambiguated_accuracy\": df[f\"{method}_disambiguated_question_answered_by_gpt35_correct\"]\n",
    "                        .apply(lambda x: np.mean(json.loads(x)))\n",
    "                        .mean(),\n",
    "                    }\n",
    "                ]\n",
    "            ),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"./data/{dataset_name}_ambiguous_top{top_n}+DOMAIN+LLM+Intent+MLM+TE+LLM+eval.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
